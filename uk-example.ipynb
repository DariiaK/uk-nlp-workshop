{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоматичне опрацювання української мови"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сегментація тексту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаймо текст \"Тигроловів\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tyhrolovy.txt\", \"r\") as f:\n",
    "    tyhrolovy_raw = f.read()\n",
    "\n",
    "print(\"У тексті є {} символів.\".format(len(tyhrolovy_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tyhrolovy_raw[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сирий текст** варто сегментувати на абзаци, речення, слова. Для цього використаємо бібліотеку [tokenize_uk](https://github.com/lang-uk/tokenize-uk).\n",
    "\n",
    "Як ви гадаєте:\n",
    "- які бувають складнощі автоматичного розбиття тексту на речення?\n",
    "- які бувають складнощі автоматичного розбиття тексту на слова?\n",
    "- які бувають складнощі автоматичного розбиття тексту на абзаци?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize_uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyhrolovy_words = tokenize_uk.tokenize_words(tyhrolovy_raw)\n",
    "\n",
    "print(\"У тексті є {} слів.\".format(len(tyhrolovy_words)))\n",
    "print()\n",
    "print(tyhrolovy_words[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyhrolovy_tokenized = tokenize_uk.tokenize_text(tyhrolovy_raw)\n",
    "\n",
    "for i in tyhrolovy_tokenized[:8]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Частиномовний аналіз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поговорімо про складнощі автоматичного частиномовного аналізу:\n",
    "- які слова можуть позначати різні частини мови?\n",
    "- які частини мови може позначати словоформа *\"край\"*? *\"прав\"*? *\"багатій\"*?\n",
    "- чи є неоднозначність у фразі *\"коло друзів та незнайомців\"*?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Більше прикладів:\n",
    "\n",
    "<img src=\"img/ambiguous-pos.png\" alt=\"Приклади слів, що позначають кілька частин мови\" width=\"40%\" height=\"40%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бібліотека [pymorphy2](https://github.com/kmike/pymorphy2) надає всі можливі варіанти розбору кожного слова, проте не визначає правильний розбір у контексті."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"край\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"прав\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Випробуйте інші слова. Гляньте на аналіз багатозначних слів (\"до\", \"того\") та нестандартних слів (\"євробляха\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Як із цим працювати?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0].tag.POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0].tag.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[0].tag.animacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse(\"багатій\")[3].tag.animacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Погляньмо на леми першого речення \"Тигроловів\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tyhrolovy_words[9:32]:\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    print(\"{:10}\\t{}\".format(word, parsed_word.normal_form))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tyhrolovy_words[9:32]:\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    print(\"{:10}\\t{:10}\\t{}\".format(word, parsed_word.normal_form, parsed_word.tag.POS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Частотний аналіз тексту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проведімо аналіз усіх слів у творах *\"Тигролови\"* та *\"Собор\"*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sobor.txt\", \"r\") as f:\n",
    "    sobor_raw = f.read()\n",
    "    sobor_words = tokenize_uk.tokenize_words(sobor_raw)\n",
    "\n",
    "print(\"У тексті є {} слів.\".format(len(sobor_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_t = [morph.parse(word)[0] for word in tyhrolovy_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_s = [morph.parse(word)[0] for word in sobor_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Як знайти найчастотніші слова в романі?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_freq(corpus, n):\n",
    "    \"Return the most common words.\"\n",
    "    words = Counter()\n",
    "    for word in corpus:\n",
    "        words[word.word] += 1\n",
    "    return words.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як можна покращити функцію **most_freq**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq(corpus, n):\n",
    "    \"Return the most common lemmas.\"\n",
    "    words = Counter()\n",
    "    for word in corpus:\n",
    "        if word.tag.POS in {\"NOUN\", \"VERB\", \"ADJF\"}:\n",
    "            words[word.normal_form] += 1\n",
    "    return words.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMONLY_CONFUSED = {'бути', 'до', 'йога', 'мен', 'перед', 'про', 'тога'}\n",
    "\n",
    "def most_freq(corpus, n):\n",
    "    \"Return the most common lemmas.\"\n",
    "    words = Counter()\n",
    "    for word in corpus:\n",
    "        if word.tag.POS in {\"NOUN\", \"VERB\", \"ADJF\"} and word.normal_form not in COMMONLY_CONFUSED:\n",
    "            words[word.normal_form] += 1\n",
    "    return words.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Як знайти найчастотніші колокації в романі?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_colloc(corpus, n):\n",
    "    \"Return the most common adjective-noun collocations.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(1, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        prev_word = corpus[i-1]\n",
    "        if word.tag.POS == \"NOUN\" and prev_word.tag.POS == \"ADJF\":\n",
    "            collocs[(prev_word.normal_form, word.normal_form)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_colloc_for_noun(corpus, n, noun):\n",
    "    \"Return the most common adjective-noun collocations with a specified noun.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(1, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        prev_word = corpus[i-1]\n",
    "        if word.normal_form == noun and prev_word.tag.POS == \"ADJF\":\n",
    "            collocs[(prev_word.normal_form, word.normal_form)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_for_noun(corpus_t, 20, \"ніч\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_for_noun(corpus_s, 20, \"ніч\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Спробуйте інші іменники, прикметники чи контексти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_colloc_for_adj(corpus, n, adj):\n",
    "    \"Return the most common adjective-noun collocations with a specified adjective.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(1, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        prev_word = corpus[i-1]\n",
    "        if word.tag.POS == \"NOUN\" and prev_word.normal_form == adj:\n",
    "            collocs[(prev_word.normal_form, word.normal_form)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_for_adj(corpus_t, 20, \"золотий\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_for_adj(corpus_s, 20, \"золотий\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_colloc_anim(corpus, n):\n",
    "    \"Return the most common adjective-noun collocations with animate nouns.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(1, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        prev_word = corpus[i-1]\n",
    "        if word.tag.POS == \"NOUN\" and word.tag.animacy == \"anim\" and prev_word.tag.POS == \"ADJF\":\n",
    "            collocs[(prev_word.normal_form, word.normal_form)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_anim(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc_anim(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Порівняйте колокації для іменників жіночого роду з колокаціями для іменників чоловічого роду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_prep_adj_noun(corpus, n):\n",
    "    \"Return the most common prep-adj-noun collocations.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(2, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        if word.tag.POS == \"NOUN\" and corpus[i-1].tag.POS == \"ADJF\" and corpus[i-2].tag.POS == \"PREP\":\n",
    "            collocs[(corpus[i-2].word, corpus[i-1].word, word.word)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_prep_adj_noun(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_prep_adj_noun(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_verb_prep_noun(corpus, n):\n",
    "    \"Return the most common verb-prep-noun collocations.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(2, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        if word.tag.POS == \"NOUN\" and corpus[i-1].tag.POS == \"PREP\" and corpus[i-2].tag.POS == \"VERB\":\n",
    "            collocs[(corpus[i-2].normal_form, corpus[i-1].word, word.word)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_verb_prep_noun(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_verb_prep_noun(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_freq_conj_adj(corpus, n):\n",
    "    \"Return the most common adj-and-adj collocations.\"\n",
    "    collocs = Counter()\n",
    "    for i in range(2, len(corpus)):\n",
    "        word = corpus[i]\n",
    "        if word.tag.POS == \"ADJF\" and corpus[i-1].word == \"і\" and corpus[i-2].tag.POS == \"ADJF\":\n",
    "            collocs[(corpus[i-2].normal_form, corpus[i-1].word, word.normal_form)] += 1\n",
    "    return collocs.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_conj_adj(corpus_t, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_conj_adj(corpus_s, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Як дослідити контексти слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_concordance(corpus, lemma, n):\n",
    "    contexts = []\n",
    "    for i in range(len(corpus)):\n",
    "        if corpus[i].normal_form == lemma:\n",
    "            left_context = corpus[max(0, i-5) : i]\n",
    "            right_context = corpus[i+1 : min(i+6, len(corpus))]\n",
    "            left = \" \".join([word.word for word in left_context])\n",
    "            right = \" \".join([word.word for word in right_context])\n",
    "            contexts.append(\"{:30}\\t{:10}\\t{}\".format(left, corpus[i].word, right))\n",
    "    return contexts[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in show_concordance(corpus_t, \"спати\", 20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in show_concordance(corpus_s, \"спати\", 20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А як щодо інших текстів?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопіюйте текст будь-якої новини. Наприклад, https://hromadske.ua/posts/ukrayina-evakuyuye-z-uhanya-razom-zi-svoyimi-gromadyanami-do-25-inozemciv-moz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"\"\"\n",
    "В Міністерстві охорони здоров’я повідомили, що Україна евакуює з карантинного міста Ухань китайської провінції Хубей 49 українців та до 25 іноземних громадян через смертельний коронавірус.\n",
    "Про це на брифінгу розповів заступник міністра охорони здоров’я Віктор Ляшко.\n",
    "\n",
    "«До 25 іноземних громадян. Хто ці особи вирішує Міністерство закордонних справ по дипломатичних каналах. Але вони усі будуть однаково проходити обсервацію, без різниці з якої країни», — зазначив чиновник.\n",
    "\n",
    "Також він додав, що наразі МОЗ обрало два медзаклади, куди доправлять евакуйованих на 14-денний карантин.\n",
    "\n",
    "«Сьогодні я їх не можу озвучити, але вони є, вони визначені і по них ведеться повна підготовка. Один основний, один резервний на випадок, якщо щось станеться під час моменту евакуації», — сказав Ляшко.\n",
    "\n",
    "На брифінгу він також повідомив, що евакуацію українців з китайської провінції Хубей, яка є епіцентром спалаху коронавірусу, знову перенесли. Раніше очікувалося, що літак з українцями прибуде у середу 19 лютого, тепер його очікують у четвер, 20 лютого.\n",
    "\n",
    "Раніше Міністерство закордонних справ Аргентини висловило подяку Україні за те, що українська влада погодилась разом зі своїми громадянами евакуювати й громадян Аргентини з китайського Уханя, епіцентру поширення коронавірусу. Скільки саме аргентинців забере український літак з Уханя, відомство не уточнило.\n",
    "\n",
    "За останніми даними, кількість людей, інфікованих китайським коронавірусом, збільшилась до 71 331. Через вірус померли 1 775 пацієнтів. У Гонконгу зафіксували 57 випадків інфікування та один смертельний випадок.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_news = [morph.parse(word)[0] for word in tokenize_uk.tokenize_words(news)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq(corpus_news, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_colloc(corpus_news, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Продовження заняття можна знайти за цим посиланням:\n",
    "http://tiny.cc/0p63jz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
